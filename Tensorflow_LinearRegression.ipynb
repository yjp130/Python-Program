{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_LinearRegression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk5QC0WBzwMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorflow import\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcA9vVT9SavU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#학습할 데이터\n",
        "x_data=[1,2,3,4,5]\n",
        "y_data=[10,20,30,40,50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnXPyiLPSjJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 가중치와 바이어스를 -1~1사이의 균등분포 값을 갖는 무작위 값으로 설정\n",
        "W=tf.Variable(tf.random_uniform([1],-1.0,1.0))\n",
        "b=tf.Variable(tf.random_uniform([1],-1.0,1.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ3pKxoRTkMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9e071b4-fef8-4882-f262-d3114d674ab5"
      },
      "source": [
        "print(W)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KfnYy_DT0M3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "043784d2-4ff5-43e5-fb5f-7f4bfab1910a"
      },
      "source": [
        "print(b)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zYPpckcT2eG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a40a76d4-6ea7-47b9-910b-64c0977e094d"
      },
      "source": [
        "X=tf.placeholder(tf.float32, name='X')\n",
        "Y=tf.placeholder(tf.float32, name='Y')\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"X:0\", dtype=float32)\n",
            "Tensor(\"Y:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmhlNmN6UCK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# score 함수 만들기\n",
        "score=W*X + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjaLWvAaUIw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "985ab36c-ac5d-423a-e598-a3d65d108fb0"
      },
      "source": [
        "# 손실함수(loss function) 만들기, simple한 loss function 사용.\n",
        "# score에서 실제 Y값을 뺀 것의 제곱의 평균을 loss로 사용하겠다.\n",
        "\n",
        "loss=tf.reduce_mean(tf.square(score-Y))\n",
        "loss"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TMb05AEUiif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc9a95f5-8088-4ca1-dfc0-3c6770683b7a"
      },
      "source": [
        "# 최적화 함수(경사하강법)\n",
        "# GradientDescentOptimizer 객체 만들기\n",
        "# learning_rate는 학습 속도로 0.01로 주겠다.\n",
        "\n",
        "optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "# GradientDescentOptimizer에 최적화 방법을 loss가 최소가 되게하는 minimize() 메서드 사용하기\n",
        "\n",
        "train_op=optimizer.minimize(loss)\n",
        "train_op"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'GradientDescent_2' type=NoOp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K_liIflVetj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04402af1-b07d-42a3-ec32-6b38f6a550b3"
      },
      "source": [
        "# 세션을 with구문으로 열자.\n",
        "with tf.Session() as sess:\n",
        "# 값을 초기화 하는 함수를 먼저 실행한다.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "# training data로 101번 학습 시키기\n",
        "# 학습시 경사하강법을 최적화 함수로 사용하고, loss 값을 최소가 되게 만든다.\n",
        "# 데이터는 플레이스홀더 X에는 x_data를 넣어주고\n",
        "# 플레이스 홀더 Y에는 y_data를 넣어준다.\n",
        "# 값을 2개 반환 받게 되는데 loss값만 loss_val 변수로 저장하자.\n",
        "  for step in range(100):\n",
        "    _, loss_val = sess.run([train_op, loss], feed_dict={X:x_data, Y:y_data})\n",
        "  # 횟수, cost, W, B 찍어보기\n",
        "    print(step, 'Loss = %-10.5f' % loss_val, 'W = %10.6f' % sess.run(W), 'B = %10.6f' % sess.run(b))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Loss = 1245.97168 W =   1.801464 B =   0.263011\n",
            "1 Loss = 726.50720  W =   3.589361 B =   0.749663\n",
            "2 Loss = 423.78622  W =   4.954722 B =   1.119308\n",
            "3 Loss = 247.37265  W =   5.997525 B =   1.399639\n",
            "4 Loss = 144.56474  W =   6.794091 B =   1.611794\n",
            "5 Loss = 84.65068   W =   7.402683 B =   1.771913\n",
            "6 Loss = 49.73296   W =   7.867778 B =   1.892314\n",
            "7 Loss = 29.38193   W =   8.223329 B =   1.982401\n",
            "8 Loss = 17.51963   W =   8.495253 B =   2.049353\n",
            "9 Loss = 10.60420   W =   8.703336 B =   2.098651\n",
            "10 Loss = 6.57158    W =   8.862682 B =   2.134478\n",
            "11 Loss = 4.21892    W =   8.984823 B =   2.160027\n",
            "12 Loss = 2.84528    W =   9.078561 B =   2.177737\n",
            "13 Loss = 2.04218    W =   9.150613 B =   2.189469\n",
            "14 Loss = 1.57158    W =   9.206110 B =   2.196643\n",
            "15 Loss = 1.29476    W =   9.248967 B =   2.200343\n",
            "16 Loss = 1.13088    W =   9.282174 B =   2.201398\n",
            "17 Loss = 1.03285    W =   9.308012 B =   2.200440\n",
            "18 Loss = 0.97319    W =   9.328223 B =   2.197950\n",
            "19 Loss = 0.93592    W =   9.344137 B =   2.194298\n",
            "20 Loss = 0.91171    W =   9.356770 B =   2.189764\n",
            "21 Loss = 0.89513    W =   9.366895 B =   2.184562\n",
            "22 Loss = 0.88301    W =   9.375104 B =   2.178857\n",
            "23 Loss = 0.87351    W =   9.381849 B =   2.172774\n",
            "24 Loss = 0.86555    W =   9.387476 B =   2.166407\n",
            "25 Loss = 0.85850    W =   9.392247 B =   2.159831\n",
            "26 Loss = 0.85201    W =   9.396363 B =   2.153099\n",
            "27 Loss = 0.84585    W =   9.399978 B =   2.146255\n",
            "28 Loss = 0.83990    W =   9.403207 B =   2.139332\n",
            "29 Loss = 0.83409    W =   9.406141 B =   2.132353\n",
            "30 Loss = 0.82838    W =   9.408849 B =   2.125337\n",
            "31 Loss = 0.82274    W =   9.411382 B =   2.118299\n",
            "32 Loss = 0.81716    W =   9.413780 B =   2.111251\n",
            "33 Loss = 0.81163    W =   9.416074 B =   2.104199\n",
            "34 Loss = 0.80614    W =   9.418285 B =   2.097150\n",
            "35 Loss = 0.80069    W =   9.420434 B =   2.090110\n",
            "36 Loss = 0.79528    W =   9.422532 B =   2.083082\n",
            "37 Loss = 0.78991    W =   9.424590 B =   2.076068\n",
            "38 Loss = 0.78458    W =   9.426616 B =   2.069072\n",
            "39 Loss = 0.77928    W =   9.428616 B =   2.062093\n",
            "40 Loss = 0.77402    W =   9.430594 B =   2.055135\n",
            "41 Loss = 0.76880    W =   9.432555 B =   2.048196\n",
            "42 Loss = 0.76361    W =   9.434502 B =   2.041279\n",
            "43 Loss = 0.75845    W =   9.436435 B =   2.034383\n",
            "44 Loss = 0.75333    W =   9.438356 B =   2.027509\n",
            "45 Loss = 0.74825    W =   9.440268 B =   2.020658\n",
            "46 Loss = 0.74320    W =   9.442169 B =   2.013828\n",
            "47 Loss = 0.73818    W =   9.444062 B =   2.007022\n",
            "48 Loss = 0.73320    W =   9.445948 B =   2.000237\n",
            "49 Loss = 0.72825    W =   9.447825 B =   1.993476\n",
            "50 Loss = 0.72333    W =   9.449696 B =   1.986737\n",
            "51 Loss = 0.71845    W =   9.451558 B =   1.980020\n",
            "52 Loss = 0.71360    W =   9.453414 B =   1.973327\n",
            "53 Loss = 0.70878    W =   9.455263 B =   1.966655\n",
            "54 Loss = 0.70400    W =   9.457106 B =   1.960006\n",
            "55 Loss = 0.69924    W =   9.458942 B =   1.953380\n",
            "56 Loss = 0.69452    W =   9.460773 B =   1.946776\n",
            "57 Loss = 0.68983    W =   9.462596 B =   1.940194\n",
            "58 Loss = 0.68518    W =   9.464414 B =   1.933634\n",
            "59 Loss = 0.68055    W =   9.466225 B =   1.927096\n",
            "60 Loss = 0.67596    W =   9.468029 B =   1.920581\n",
            "61 Loss = 0.67140    W =   9.469828 B =   1.914088\n",
            "62 Loss = 0.66686    W =   9.471621 B =   1.907616\n",
            "63 Loss = 0.66236    W =   9.473407 B =   1.901167\n",
            "64 Loss = 0.65789    W =   9.475187 B =   1.894739\n",
            "65 Loss = 0.65345    W =   9.476962 B =   1.888333\n",
            "66 Loss = 0.64904    W =   9.478730 B =   1.881949\n",
            "67 Loss = 0.64466    W =   9.480493 B =   1.875586\n",
            "68 Loss = 0.64030    W =   9.482249 B =   1.869244\n",
            "69 Loss = 0.63598    W =   9.484000 B =   1.862925\n",
            "70 Loss = 0.63169    W =   9.485744 B =   1.856626\n",
            "71 Loss = 0.62743    W =   9.487483 B =   1.850349\n",
            "72 Loss = 0.62319    W =   9.489216 B =   1.844093\n",
            "73 Loss = 0.61898    W =   9.490943 B =   1.837858\n",
            "74 Loss = 0.61480    W =   9.492664 B =   1.831644\n",
            "75 Loss = 0.61065    W =   9.494379 B =   1.825451\n",
            "76 Loss = 0.60653    W =   9.496089 B =   1.819280\n",
            "77 Loss = 0.60244    W =   9.497792 B =   1.813129\n",
            "78 Loss = 0.59837    W =   9.499490 B =   1.806999\n",
            "79 Loss = 0.59433    W =   9.501183 B =   1.800889\n",
            "80 Loss = 0.59032    W =   9.502869 B =   1.794801\n",
            "81 Loss = 0.58633    W =   9.504550 B =   1.788733\n",
            "82 Loss = 0.58238    W =   9.506225 B =   1.782685\n",
            "83 Loss = 0.57845    W =   9.507895 B =   1.776658\n",
            "84 Loss = 0.57454    W =   9.509559 B =   1.770651\n",
            "85 Loss = 0.57066    W =   9.511217 B =   1.764664\n",
            "86 Loss = 0.56681    W =   9.512870 B =   1.758698\n",
            "87 Loss = 0.56298    W =   9.514517 B =   1.752752\n",
            "88 Loss = 0.55918    W =   9.516158 B =   1.746826\n",
            "89 Loss = 0.55541    W =   9.517794 B =   1.740920\n",
            "90 Loss = 0.55166    W =   9.519423 B =   1.735034\n",
            "91 Loss = 0.54793    W =   9.521049 B =   1.729168\n",
            "92 Loss = 0.54424    W =   9.522668 B =   1.723322\n",
            "93 Loss = 0.54056    W =   9.524282 B =   1.717495\n",
            "94 Loss = 0.53691    W =   9.525890 B =   1.711688\n",
            "95 Loss = 0.53329    W =   9.527493 B =   1.705901\n",
            "96 Loss = 0.52969    W =   9.529091 B =   1.700133\n",
            "97 Loss = 0.52611    W =   9.530683 B =   1.694385\n",
            "98 Loss = 0.52256    W =   9.532269 B =   1.688657\n",
            "99 Loss = 0.51903    W =   9.533851 B =   1.682947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbxLVwKrXDnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76189dfa-6906-4652-c7c8-510335bfcc97"
      },
      "source": [
        "#세션을 with구문으로 열자.\n",
        "with tf.Session() as sess:\n",
        "# 값을 초기화 하는 함수를 먼저 실행한다.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "# 0~1000 까지 1001번 학습시킨다.\n",
        "# 학습시 경사하강법을 최적화 함수로 사용하고, loss 값을 최소가 되게 만든다.\n",
        "# 데이터는 플레이스홀더 X에는 x_data를 넣어주고\n",
        "# 플레이스 홀더 Y에는 y_data를 넣어준다.\n",
        "# 값을 2개 반환 받게 되는데 loss값만 loss_val 변수로 저장하자.\n",
        "  for step in range(1001):\n",
        "      \n",
        "    _, loss_val = sess.run([train_op, loss], feed_dict = {X:x_data, Y:y_data})\n",
        "  # 10번마다 횟수, loss값, W값, b값을 확인해보자.\n",
        "    if step%10 ==0:\n",
        "      print(step, loss_val, sess.run(W), sess.run(b))\n",
        "      \n",
        "  print('Y = {Weight} * X + {Bias}'.format(Weight = sess.run(W), Bias = sess.run(b)))\n",
        "  # score 함수에 x값으로 5를 넣어 예측되는 Y값을 보자. X라는 플레이스홀더를 이용하자.\n",
        "  print('X:5, Y:', sess.run(score, feed_dict={X:5}))\n",
        "  # score 함수에 x값으로 2.5를 넣어 예측되는 Y값을 보자. X라는 플레이스홀더를 이용하자.\n",
        "  print('X:2.5, Y:', sess.run(score, feed_dict={X:2.5}))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1255.1609 [1.7609015] [0.30186126]\n",
            "10 6.6507707 [8.848367] [2.1789305]\n",
            "20 0.9472812 [9.344604] [2.2331998]\n",
            "30 0.86144906 [9.397201] [2.1673584]\n",
            "40 0.8049253 [9.419341] [2.095759]\n",
            "50 0.75220937 [9.438817] [2.026009]\n",
            "60 0.70294654 [9.457514] [1.9585457]\n",
            "70 0.65690976 [9.475578] [1.8933268]\n",
            "80 0.6138885 [9.493041] [1.8302797]\n",
            "90 0.57368624 [9.509923] [1.7693323]\n",
            "100 0.53611404 [9.526242] [1.7104138]\n",
            "110 0.5010036 [9.542019] [1.6534574]\n",
            "120 0.46819216 [9.55727] [1.5983974]\n",
            "130 0.43753093 [9.572013] [1.5451709]\n",
            "140 0.40887618 [9.586266] [1.4937168]\n",
            "150 0.38209763 [9.600042] [1.4439759]\n",
            "160 0.35707393 [9.61336] [1.3958915]\n",
            "170 0.33368912 [9.626236] [1.3494086]\n",
            "180 0.31183562 [9.638681] [1.3044734]\n",
            "190 0.29141277 [9.650714] [1.2610347]\n",
            "200 0.27232844 [9.662344] [1.2190425]\n",
            "210 0.25449347 [9.673588] [1.1784489]\n",
            "220 0.23782666 [9.684458] [1.1392069]\n",
            "230 0.22225058 [9.694965] [1.1012714]\n",
            "240 0.20769513 [9.705123] [1.0645993]\n",
            "250 0.19409403 [9.714942] [1.0291486]\n",
            "260 0.18138249 [9.724435] [0.9948783]\n",
            "270 0.16950314 [9.733611] [0.9617491]\n",
            "280 0.1584026 [9.742481] [0.92972314]\n",
            "290 0.14802803 [9.751057] [0.89876336]\n",
            "300 0.13833457 [9.759348] [0.8688344]\n",
            "310 0.12927438 [9.767361] [0.8399019]\n",
            "320 0.12080809 [9.775107] [0.8119332]\n",
            "330 0.11289592 [9.782597] [0.78489584]\n",
            "340 0.1055022 [9.789836] [0.7587589]\n",
            "350 0.09859288 [9.796835] [0.7334922]\n",
            "360 0.092136115 [9.8036] [0.70906675]\n",
            "370 0.086101934 [9.810141] [0.6854546]\n",
            "380 0.08046295 [9.8164625] [0.6626289]\n",
            "390 0.07519306 [9.822574] [0.6405635]\n",
            "400 0.07026897 [9.828482] [0.619233]\n",
            "410 0.06566684 [9.834194] [0.5986129]\n",
            "420 0.06136624 [9.839716] [0.5786788]\n",
            "430 0.05734719 [9.845054] [0.5594086]\n",
            "440 0.053591542 [9.850213] [0.5407802]\n",
            "450 0.050081648 [9.855201] [0.5227722]\n",
            "460 0.046801753 [9.860023] [0.5053639]\n",
            "470 0.043736838 [9.864683] [0.4885353]\n",
            "480 0.040872555 [9.869189] [0.47226715]\n",
            "490 0.03819596 [9.873546] [0.4565407]\n",
            "500 0.035693884 [9.877756] [0.44133803]\n",
            "510 0.033356465 [9.881827] [0.42664135]\n",
            "520 0.031171897 [9.885762] [0.41243404]\n",
            "530 0.02913076 [9.889566] [0.39870006]\n",
            "540 0.027222589 [9.893245] [0.38542315]\n",
            "550 0.025439728 [9.896799] [0.37258846]\n",
            "560 0.02377372 [9.900235] [0.36018127]\n",
            "570 0.022216825 [9.903557] [0.34818736]\n",
            "580 0.020761836 [9.906769] [0.3365932]\n",
            "590 0.019402042 [9.909874] [0.32538494]\n",
            "600 0.018131483 [9.912874] [0.31454995]\n",
            "610 0.016944136 [9.915776] [0.30407533]\n",
            "620 0.015834237 [9.918581] [0.29394954]\n",
            "630 0.014797082 [9.921293] [0.28416067]\n",
            "640 0.013828186 [9.923913] [0.27469787]\n",
            "650 0.012922436 [9.926447] [0.26555043]\n",
            "660 0.012076015 [9.928897] [0.25670743]\n",
            "670 0.01128533 [9.931264] [0.248159]\n",
            "680 0.010546406 [9.933553] [0.23989522]\n",
            "690 0.009855615 [9.935766] [0.23190661]\n",
            "700 0.009210059 [9.937905] [0.22418377]\n",
            "710 0.008606802 [9.939973] [0.21671827]\n",
            "720 0.008043246 [9.941971] [0.20950146]\n",
            "730 0.0075164484 [9.943904] [0.20252526]\n",
            "740 0.0070242397 [9.945772] [0.19578107]\n",
            "750 0.0065641776 [9.947577] [0.18926144]\n",
            "760 0.006134369 [9.949324] [0.18295899]\n",
            "770 0.0057325615 [9.951011] [0.17686664]\n",
            "780 0.005357095 [9.9526415] [0.17097707]\n",
            "790 0.005006302 [9.954219] [0.16528381]\n",
            "800 0.004678496 [9.955744] [0.15978003]\n",
            "810 0.0043720054 [9.957217] [0.1544593]\n",
            "820 0.004085646 [9.958642] [0.1493156]\n",
            "830 0.0038180747 [9.96002] [0.1443431]\n",
            "840 0.0035679836 [9.96135] [0.13953647]\n",
            "850 0.0033343495 [9.962638] [0.13488978]\n",
            "860 0.0031159625 [9.9638815] [0.13039792]\n",
            "870 0.0029119314 [9.965085] [0.12605572]\n",
            "880 0.0027211655 [9.966248] [0.12185801]\n",
            "890 0.0025429998 [9.967372] [0.11780001]\n",
            "900 0.0023763666 [9.968458] [0.11387718]\n",
            "910 0.0022207778 [9.969508] [0.11008497]\n",
            "920 0.0020753418 [9.970524] [0.10641915]\n",
            "930 0.0019394122 [9.971505] [0.10287532]\n",
            "940 0.0018124128 [9.972454] [0.09944957]\n",
            "950 0.00169375 [9.9733715] [0.09613791]\n",
            "960 0.0015828531 [9.974258] [0.09293645]\n",
            "970 0.0014791966 [9.975116] [0.08984162]\n",
            "980 0.0013823144 [9.9759445] [0.08684973]\n",
            "990 0.0012917307 [9.976746] [0.0839575]\n",
            "1000 0.0012071233 [9.977519] [0.08116175]\n",
            "Y = [9.977519] * X + [0.08116175]\n",
            "X:5, Y: [49.968758]\n",
            "X:2.5, Y: [25.02496]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmMGJ8fQYfxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}